<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Synced Transcription</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
        }

        .content {
            height: 100vh;
            overflow-y: scroll; /* Enables scrolling */
            padding: 20px;
        }

        .segment {
            margin-bottom: 20px;
        }

        .highlight {
            color: red;
            background-color: white;
            transition: background-color 0.5s ease; /* Smooth highlight effect */
        }
    </style>
</head>
<body>
    <audio id="audio" controls>
        <source src="{{mp3file}}" type="audio/mpeg">
        Your browser does not support the audio element.
    </audio>

    <div class="content" id="transcription">

    </div>

    <script>
document.addEventListener("DOMContentLoaded", () => {
    const audio = document.getElementById("audio");
    const transcriptionContainer = document.getElementById("transcription");

    const whisperData = {{{transcript}}}
    
   
    // Process the data into paragraphs and phrases
    function renderTranscription(data) {
        const paragraph = document.createElement("p");

        data.forEach(segment => {
            const phrases = segment.text.split(/(?<=\.)|(?<=\?)|(?<=\!)/g); // Split text by punctuation

            phrases.forEach(phrase => {
                const span = document.createElement("span");
                span.classList.add("phrase");
                span.dataset.start = segment.start;
                span.dataset.end = segment.end;
                span.textContent = phrase.trim() + " ";
                paragraph.appendChild(span);
            });
        });

        transcriptionContainer.appendChild(paragraph);
    }

    // Render the Whisper data
    renderTranscription(whisperData);

    // Highlight current phrase based on audio time
    const phrases = document.querySelectorAll(".phrase");
    let currentPhraseIndex = -1;

    function highlightCurrentPhrase() {
        const currentTime = audio.currentTime;

        for (let i = 0; i < phrases.length; i++) {
            const start = parseFloat(phrases[i].dataset.start);
            const end = parseFloat(phrases[i].dataset.end);

            if (currentTime >= start && currentTime < end) {
                if (currentPhraseIndex !== i) {
                    // Remove previous highlight
                    if (currentPhraseIndex !== -1) {
                        phrases[currentPhraseIndex].classList.remove("highlight");
                    }

                    // Highlight new phrase
                    phrases[i].classList.add("highlight");
                    phrases[i].scrollIntoView({ behavior: "smooth", block: "center" });

                    currentPhraseIndex = i;
                }
                return;
            }
        }

        // Remove highlight if no phrase matches
        if (currentPhraseIndex !== -1) {
            phrases[currentPhraseIndex].classList.remove("highlight");
            currentPhraseIndex = -1;
        }
    }

    // Attach the timeupdate event listener
    audio.addEventListener("timeupdate", highlightCurrentPhrase);
});
    </script>
</body>
</html>