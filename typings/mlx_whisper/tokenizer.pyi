"""
This type stub file was generated by pyright.
"""

import tiktoken
from dataclasses import dataclass
from functools import cached_property, lru_cache
from typing import Dict, List, Optional, Tuple

LANGUAGES = ...
TO_LANGUAGE_CODE = ...
@dataclass
class Tokenizer:
    """A thin wrapper around `tiktoken` providing quick access to special tokens"""
    encoding: tiktoken.Encoding
    num_languages: int
    language: Optional[str] = ...
    task: Optional[str] = ...
    sot_sequence: Tuple[int] = ...
    special_tokens: Dict[str, int] = ...
    def __post_init__(self): # -> None:
        ...
    
    def encode(self, text, **kwargs): # -> list[int]:
        ...
    
    def decode(self, token_ids: List[int], **kwargs) -> str:
        ...
    
    def decode_with_timestamps(self, token_ids: List[int], **kwargs) -> str:
        """
        Timestamp tokens are above other special tokens' id range and are ignored by `decode()`.
        This method decodes given tokens with timestamps tokens annotated, e.g. "<|1.08|>".
        """
        ...
    
    @cached_property
    def eot(self) -> int:
        ...
    
    @cached_property
    def transcribe(self) -> int:
        ...
    
    @cached_property
    def translate(self) -> int:
        ...
    
    @cached_property
    def sot(self) -> int:
        ...
    
    @cached_property
    def sot_lm(self) -> int:
        ...
    
    @cached_property
    def sot_prev(self) -> int:
        ...
    
    @cached_property
    def no_speech(self) -> int:
        ...
    
    @cached_property
    def no_timestamps(self) -> int:
        ...
    
    @cached_property
    def timestamp_begin(self) -> int:
        ...
    
    @cached_property
    def language_token(self) -> int:
        """Returns the token id corresponding to the value of the `language` field"""
        ...
    
    def to_language_token(self, language): # -> int:
        ...
    
    @cached_property
    def all_language_tokens(self) -> Tuple[int]:
        ...
    
    @cached_property
    def all_language_codes(self) -> Tuple[str]:
        ...
    
    @cached_property
    def sot_sequence_including_notimestamps(self) -> Tuple[int]:
        ...
    
    @cached_property
    def non_speech_tokens(self) -> Tuple[int]:
        """
        Returns the list of tokens to suppress in order to avoid any speaker tags or non-speech
        annotations, to prevent sampling texts that are not actually spoken in the audio, e.g.

        - ♪♪♪
        - ( SPEAKING FOREIGN LANGUAGE )
        - [DAVID] Hey there,

        keeping basic punctuations like commas, periods, question marks, exclamation points, etc.
        """
        ...
    
    def split_to_word_tokens(self, tokens: List[int]): # -> tuple[list[Any], list[Any]]:
        ...
    
    def split_tokens_on_unicode(self, tokens: List[int]): # -> tuple[list[Any], list[Any]]:
        ...
    
    def split_tokens_on_spaces(self, tokens: List[int]): # -> tuple[list[Any], list[Any]]:
        ...
    


@lru_cache(maxsize=None)
def get_encoding(name: str = ..., num_languages: int = ...): # -> Encoding:
    ...

@lru_cache(maxsize=None)
def get_tokenizer(multilingual: bool, *, num_languages: int = ..., language: Optional[str] = ..., task: Optional[str] = ...) -> Tokenizer:
    ...

